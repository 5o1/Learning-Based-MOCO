{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7c1ae6bfafd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize environment for reproducibility\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file in trainlist:  12344\n",
      "file in vallist:  3764\n",
      "file in testlist:  1464\n",
      "file in showlist:  4\n"
     ]
    }
   ],
   "source": [
    "# format: filename index_of_slice\n",
    "trainlistpath = \"/home/liyy/data1/moco/datasets/.Fastmri_pics/trainlist.txt\"\n",
    "vallistpath = \"/home/liyy/data1/moco/datasets/.Fastmri_pics/vallist.txt\"\n",
    "testlistpath = \"/home/liyy/data1/moco/datasets/.Fastmri_pics/testlist.txt\"\n",
    "showlistpath = \"/home/liyy/data1/moco/datasets/.Fastmri_pics/showlist.txt\"\n",
    "\n",
    "with open(trainlistpath, 'r') as f:\n",
    "    trainlist = f.readlines()\n",
    "    trainlist = [(line.split()[0], int(line.split()[1])) for line in trainlist]\n",
    "\n",
    "with open(vallistpath, 'r') as f:\n",
    "    vallist = f.readlines()\n",
    "    vallist = [(line.split()[0], int(line.split()[1])) for line in vallist]\n",
    "\n",
    "with open(testlistpath, 'r') as f:\n",
    "    testlist = f.readlines()\n",
    "    testlist = [(line.split()[0], int(line.split()[1])) for line in testlist]\n",
    "\n",
    "with open(showlistpath, 'r') as f:\n",
    "    showlist = f.readlines()\n",
    "    showlist = [(line.split()[0], int(line.split()[1])) for line in showlist]\n",
    "\n",
    "print(\"file in trainlist: \", len(trainlist))\n",
    "print(\"file in vallist: \", len(vallist))\n",
    "print(\"file in testlist: \", len(testlist))\n",
    "print(\"file in showlist: \", len(showlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadtransform\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "load_keys = ['kspace']\n",
    "\n",
    "class Loadtransform(nn.Module):\n",
    "    \"\"\"Load the data to the memory\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, data):\n",
    "        # input: ismrmrd_header rss csm kspace\n",
    "        return {'kspace': data['kspace'].to(torch.complex64)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation transform\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as tf\n",
    "\n",
    "from models.mynn import functional as myf\n",
    "from torchkbnufft import KbNufft, KbNufftAdjoint, calc_tensor_spmatrix, calc_density_compensation_function, ToepNufft\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "\n",
    "class Motion(nn.Module):\n",
    "    def __init__(self, image_size = (320, 320),\n",
    "                 motion_ratio = [1, 1, 1, 1, 1], rot = 15, shift = (0.05, 0.05), scale = (0.01, 0.01), shear = (0.01, 0.01),\n",
    "                 num_spokes_full = 500, num_spokes_partial = 20, num_pts_readout = 320, oversampling_factor = 2,\n",
    "                 dtype = torch.complex64, device = torch.device('cuda')):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.rot = rot\n",
    "        self.shift = shift\n",
    "        self.scale = scale\n",
    "        self.shear = shear\n",
    "        self.num_spokes_full = num_spokes_full\n",
    "        self.num_spokes_partial = num_spokes_partial\n",
    "        self.num_pts_readout = num_pts_readout\n",
    "        self.oversampling_factor = oversampling_factor\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "\n",
    "        self.float_dtype = torch.float32 if dtype == torch.complex64 else torch.float64\n",
    "\n",
    "        self.num_motion_states = len(motion_ratio)\n",
    "        self.motion_partition = [0]\n",
    "        for ratio in motion_ratio:\n",
    "            self.motion_partition.append(self.motion_partition[-1] + ratio / sum(motion_ratio))\n",
    "        \n",
    "        self.random_motion = tf.RandomAffine(degrees=rot, translate=shift, scale=scale, shear=shear, fill=0).to(device)\n",
    "        self._nufft_obj = KbNufft(im_size=image_size, dtype=dtype, device=device)\n",
    "        self._inufft_obj = KbNufftAdjoint(im_size=image_size, dtype=dtype, device=device)\n",
    "\n",
    "        self.traj_full = self.gatraj().to(device).to(self.float_dtype)\n",
    "        self.traj_partial = self.traj_full[:self.num_spokes_partial]\n",
    "\n",
    "    def move(self, image):\n",
    "        \"\"\" input: batch, channel, height, width\n",
    "            output: motion_state, batch, channel, height, width\n",
    "        \"\"\"\n",
    "        image = myf.complex_to_real(image) # batch, channel * 2, height, width\n",
    "        resl = torch.zeros((self.num_motion_states+1), *image.shape, dtype=image.dtype, device=image.device) # motion_state batch, channel, height, width\n",
    "        resl[0] = image\n",
    "        for i in range(self.num_motion_states):\n",
    "            resl[i+1] = self.random_motion(image)\n",
    "        resl = myf.real_to_complex(resl) # motion_state, batch, channel, height, width\n",
    "        return resl\n",
    "    \n",
    "    def gatraj(self):\n",
    "        \"\"\"Get golden angle trajectory\"\"\"\n",
    "        import sys\n",
    "        import os\n",
    "        sys.path.append(os.path.join(os.environ['BART_TOOLBOX_PATH'], 'python'))\n",
    "        from bart import bart\n",
    "        traj = bart(1, f'traj -x {self.num_pts_readout} -y {self.num_spokes_full} -r -G -o {self.oversampling_factor}')\n",
    "        traj = torch.tensor(traj)[:2, :, :].real\n",
    "        traj = rearrange(traj, 'pos readout phase -> phase readout pos')\n",
    "        return traj\n",
    "\n",
    "    def ft(self, image, ktraj):\n",
    "        ktraj_shape = ktraj.shape\n",
    "        ktraj = ktraj / self.num_pts_readout * 2 * torch.pi # bart normalization to torchkbnufft normalization\n",
    "        ktraj = rearrange(ktraj, 'phase readout pos -> pos (phase readout)')\n",
    "\n",
    "        # batched nufft\n",
    "        original_shape = image.shape\n",
    "        image = rearrange(image, '... channel phase readout -> (...) channel phase readout') # nufft only accept [b h w] input\n",
    "\n",
    "        res = torch.cat([self._nufft_obj(image[i].unsqueeze(0), ktraj) for i in range(image.shape[0])], dim = 0).view(*original_shape[:-2], ktraj_shape[0], ktraj_shape[1]) # ... phase readout\n",
    "        return res\n",
    "    \n",
    "    def ift(self, kspace, ktraj):\n",
    "        ktraj_shape = ktraj.shape\n",
    "        ktraj = ktraj / self.num_pts_readout * 2 * torch.pi\n",
    "        ktraj = rearrange(ktraj, 'phase readout pos -> pos (phase readout)')\n",
    "\n",
    "        interp_mats = calc_tensor_spmatrix(ktraj,im_size=self.image_size, table_oversamp=2)\n",
    "        dcomp = calc_density_compensation_function(ktraj=ktraj, im_size=self.image_size)\n",
    "\n",
    "        # batched inufft\n",
    "        original_shape = kspace.shape\n",
    "\n",
    "        kspace = rearrange(kspace, '... channel phase readout -> (...) channel (phase readout)') # inufft only accept [b pts] input\n",
    "\n",
    "        res = torch.cat([self._inufft_obj(kspace[i].unsqueeze(0) * dcomp, ktraj, interp_mats) for i in range(kspace.shape[0])], dim=0).view(*original_shape[:-2], *self.image_size) # ... height width\n",
    "        return res\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        image = self.move(image) # motion_state, batch, channel, height, width\n",
    "        kspace = self.ft(image, self.traj_full) # motion_state, batch, channel, phase, readout\n",
    "\n",
    "        indices = torch.randperm(kspace.shape[-2])\n",
    "        kspace_mixed = torch.zeros_like(kspace[0]) # batch, channel, phase, readout\n",
    "        for state in range(self.num_motion_states):\n",
    "            kspace_mixed[:, :, indices[int(self.motion_partition[state] * indices.shape[0]):int(self.motion_partition[state+1] * indices.shape[0])], :] \\\n",
    "                = kspace[state][:, :, indices[int(self.motion_partition[state] * indices.shape[0]):int(self.motion_partition[state+1] * indices.shape[0])] , :]\n",
    "\n",
    "        image = self.ift(kspace_mixed, self.traj_full)\n",
    "        return image, kspace_mixed\n",
    "\n",
    "\n",
    "class DataAugmentation(nn.Module):\n",
    "    \"\"\"Computationally Intensive Transformations\"\"\"\n",
    "    def __init__(self, motion_simulator: nn.Module):\n",
    "        super().__init__()\n",
    "        self.motion_simulator = motion_simulator\n",
    "\n",
    "    def mean_std_norm_complex(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        real = data.real\n",
    "        imag = data.imag\n",
    "        real = (real - real.mean()) / real.std()\n",
    "        imag = (imag - imag.mean()) / imag.std()\n",
    "        return real + 1j * imag\n",
    "\n",
    "    def forward(self, data):\n",
    "        kspace = data['kspace']\n",
    "        image = myf.ktoi(kspace)\n",
    "        image = self.mean_std_norm_complex(image)\n",
    "        kspace = myf.itok(image)\n",
    "        image_after, kspace_after = self.motion_simulator(image)\n",
    "        image_after = self.mean_std_norm_complex(image_after)\n",
    "        return {\"kspace_before\":kspace, \"kspace_after\":kspace_after, \"image_before\":image, \"image_after\":image_after}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024/12/12 18:29:09][unet_radial_moco_train_20241212182909][DEBUG]logger unet_radial_moco_train_20241212182909 configuration done. Log file: exp/unet_radial_moco_train_20241212182909/train.log, Log level: 10, Console log level: 10, File log level: 20.\n",
      "[2024/12/12 18:29:09][unet_radial_moco_train_20241212182909][DEBUG]|||||Trainer now using device: cuda|||||\n",
      "[2024/12/12 18:29:09][unet_radial_moco_train_20241212182909][DEBUG]Total samples: train_loader 1543 , val_loader 471\n",
      "[2024/12/12 18:29:09][unet_radial_moco_train_20241212182909][DEBUG]|-\n",
      "train:\n",
      "  exp_name: unet_radial_moco\n",
      "  batch_size: 8\n",
      "  epoch: 11\n",
      "  learning_rate: 0.001\n",
      "  device: cuda\n",
      "  save_to: |-\n",
      "    exp/unet_radial_moco_train_20241212182909\n",
      "  loss_fn: |\n",
      "    def loss_fn(pred, true):\n",
      "        pred = mynn.complex_to_real(pred)\n",
      "        pred = mynn.real_to_complex(true)\n",
      "        return 1-ssim_fn(pred,true)\n",
      "extra_info:\n",
      "  test: '1'\n",
      "\n",
      "[2024/12/12 18:34:42][unet_radial_moco_train_20241212182909][DEBUG]|-\n",
      "=========================================================================================================\n",
      "Layer (type:depth-idx)                                  Output Shape              Param #\n",
      "=========================================================================================================\n",
      "MyModel                                                 [8, 16, 320, 320]         --\n",
      "├─Complex2Real: 1-1                                     [8, 32, 320, 320]         --\n",
      "├─UNet: 1-2                                             [8, 32, 320, 320]         --\n",
      "│    └─CheckNan: 2-1                                    [8, 32, 320, 320]         --\n",
      "│    └─CheckInf: 2-2                                    [8, 32, 320, 320]         --\n",
      "│    └─Conv2d: 2-3                                      [8, 64, 320, 320]         2,112\n",
      "│    └─Sequential: 2-4                                  --                        --\n",
      "│    │    └─Down: 3-1                                   [8, 128, 160, 160]        --\n",
      "│    │    │    └─nConv2d: 4-1                           [8, 64, 320, 320]         --\n",
      "│    │    │    │    └─Sequential: 5-1                   [8, 64, 320, 320]         --\n",
      "│    │    │    │    │    └─Conv2d: 6-1                  [8, 64, 320, 320]         36,864\n",
      "│    │    │    │    │    └─ReLU: 6-2                    [8, 64, 320, 320]         --\n",
      "│    │    │    │    │    └─Conv2d: 6-3                  [8, 64, 320, 320]         36,864\n",
      "│    │    │    └─Conv2d: 4-2                            [8, 128, 160, 160]        32,768\n",
      "│    │    └─Down: 3-2                                   [8, 256, 80, 80]          --\n",
      "│    │    │    └─nConv2d: 4-3                           [8, 128, 160, 160]        --\n",
      "│    │    │    │    └─Sequential: 5-2                   [8, 128, 160, 160]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-4                  [8, 128, 160, 160]        147,456\n",
      "│    │    │    │    │    └─ReLU: 6-5                    [8, 128, 160, 160]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-6                  [8, 128, 160, 160]        147,456\n",
      "│    │    │    └─Conv2d: 4-4                            [8, 256, 80, 80]          131,072\n",
      "│    │    └─Down: 3-3                                   [8, 512, 40, 40]          --\n",
      "│    │    │    └─nConv2d: 4-5                           [8, 256, 80, 80]          --\n",
      "│    │    │    │    └─Sequential: 5-3                   [8, 256, 80, 80]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-7                  [8, 256, 80, 80]          589,824\n",
      "│    │    │    │    │    └─ReLU: 6-8                    [8, 256, 80, 80]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-9                  [8, 256, 80, 80]          589,824\n",
      "│    │    │    └─Conv2d: 4-6                            [8, 512, 40, 40]          524,288\n",
      "│    │    └─Down: 3-4                                   [8, 1024, 20, 20]         --\n",
      "│    │    │    └─nConv2d: 4-7                           [8, 512, 40, 40]          --\n",
      "│    │    │    │    └─Sequential: 5-4                   [8, 512, 40, 40]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-10                 [8, 512, 40, 40]          2,359,296\n",
      "│    │    │    │    │    └─ReLU: 6-11                   [8, 512, 40, 40]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-12                 [8, 512, 40, 40]          2,359,296\n",
      "│    │    │    └─Conv2d: 4-8                            [8, 1024, 20, 20]         2,097,152\n",
      "│    └─Sequential: 2-5                                  [8, 1024, 20, 20]         --\n",
      "│    │    └─nConv2d: 3-5                                [8, 1024, 20, 20]         --\n",
      "│    │    │    └─Sequential: 4-9                        [8, 1024, 20, 20]         --\n",
      "│    │    │    │    └─Conv2d: 5-5                       [8, 1024, 20, 20]         9,437,184\n",
      "│    │    │    │    └─ReLU: 5-6                         [8, 1024, 20, 20]         --\n",
      "│    │    │    │    └─Conv2d: 5-7                       [8, 1024, 20, 20]         9,437,184\n",
      "│    │    └─CABlock: 3-6                                [8, 1024, 20, 20]         --\n",
      "│    │    │    └─Sequential: 4-10                       [8, 1024, 20, 20]         --\n",
      "│    │    │    │    └─Conv2d: 5-8                       [8, 1024, 20, 20]         9,437,184\n",
      "│    │    │    │    └─ReLU: 5-9                         [8, 1024, 20, 20]         --\n",
      "│    │    │    │    └─Conv2d: 5-10                      [8, 1024, 20, 20]         9,437,184\n",
      "│    │    │    └─CALayer: 4-11                          [8, 1024, 20, 20]         --\n",
      "│    │    │    │    └─AdaptiveAvgPool2d: 5-11           [8, 1024, 1, 1]           --\n",
      "│    │    │    │    └─Sequential: 5-12                  [8, 1024]                 --\n",
      "│    │    │    │    │    └─Linear: 6-13                 [8, 256]                  262,144\n",
      "│    │    │    │    │    └─ReLU: 6-14                   [8, 256]                  --\n",
      "│    │    │    │    │    └─Linear: 6-15                 [8, 1024]                 262,144\n",
      "│    └─Sequential: 2-6                                  --                        --\n",
      "│    │    └─Up: 3-7                                     [8, 512, 40, 40]          --\n",
      "│    │    │    └─ConvTranspose2d: 4-12                  [8, 512, 40, 40]          2,097,152\n",
      "│    │    │    └─nConv2d: 4-13                          [8, 1024, 40, 40]         --\n",
      "│    │    │    │    └─Sequential: 5-13                  [8, 1024, 40, 40]         --\n",
      "│    │    │    │    │    └─Conv2d: 6-16                 [8, 1024, 40, 40]         9,437,184\n",
      "│    │    │    │    │    └─ReLU: 6-17                   [8, 1024, 40, 40]         --\n",
      "│    │    │    │    │    └─Conv2d: 6-18                 [8, 1024, 40, 40]         9,437,184\n",
      "│    │    │    └─Conv2d: 4-14                           [8, 512, 40, 40]          524,288\n",
      "│    │    │    └─CABlock: 4-15                          [8, 512, 40, 40]          --\n",
      "│    │    │    │    └─Sequential: 5-14                  [8, 512, 40, 40]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-19                 [8, 512, 40, 40]          2,359,296\n",
      "│    │    │    │    │    └─ReLU: 6-20                   [8, 512, 40, 40]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-21                 [8, 512, 40, 40]          2,359,296\n",
      "│    │    │    │    └─CALayer: 5-15                     [8, 512, 40, 40]          --\n",
      "│    │    │    │    │    └─AdaptiveAvgPool2d: 6-22      [8, 512, 1, 1]            --\n",
      "│    │    │    │    │    └─Sequential: 6-23             [8, 512]                  131,072\n",
      "│    │    └─Up: 3-8                                     [8, 256, 80, 80]          --\n",
      "│    │    │    └─ConvTranspose2d: 4-16                  [8, 256, 80, 80]          524,288\n",
      "│    │    │    └─nConv2d: 4-17                          [8, 512, 80, 80]          --\n",
      "│    │    │    │    └─Sequential: 5-16                  [8, 512, 80, 80]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-24                 [8, 512, 80, 80]          2,359,296\n",
      "│    │    │    │    │    └─ReLU: 6-25                   [8, 512, 80, 80]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-26                 [8, 512, 80, 80]          2,359,296\n",
      "│    │    │    └─Conv2d: 4-18                           [8, 256, 80, 80]          131,072\n",
      "│    │    │    └─CABlock: 4-19                          [8, 256, 80, 80]          --\n",
      "│    │    │    │    └─Sequential: 5-17                  [8, 256, 80, 80]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-27                 [8, 256, 80, 80]          589,824\n",
      "│    │    │    │    │    └─ReLU: 6-28                   [8, 256, 80, 80]          --\n",
      "│    │    │    │    │    └─Conv2d: 6-29                 [8, 256, 80, 80]          589,824\n",
      "│    │    │    │    └─CALayer: 5-18                     [8, 256, 80, 80]          --\n",
      "│    │    │    │    │    └─AdaptiveAvgPool2d: 6-30      [8, 256, 1, 1]            --\n",
      "│    │    │    │    │    └─Sequential: 6-31             [8, 256]                  32,768\n",
      "│    │    └─Up: 3-9                                     [8, 128, 160, 160]        --\n",
      "│    │    │    └─ConvTranspose2d: 4-20                  [8, 128, 160, 160]        131,072\n",
      "│    │    │    └─nConv2d: 4-21                          [8, 256, 160, 160]        --\n",
      "│    │    │    │    └─Sequential: 5-19                  [8, 256, 160, 160]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-32                 [8, 256, 160, 160]        589,824\n",
      "│    │    │    │    │    └─ReLU: 6-33                   [8, 256, 160, 160]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-34                 [8, 256, 160, 160]        589,824\n",
      "│    │    │    └─Conv2d: 4-22                           [8, 128, 160, 160]        32,768\n",
      "│    │    │    └─CABlock: 4-23                          [8, 128, 160, 160]        --\n",
      "│    │    │    │    └─Sequential: 5-20                  [8, 128, 160, 160]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-35                 [8, 128, 160, 160]        147,456\n",
      "│    │    │    │    │    └─ReLU: 6-36                   [8, 128, 160, 160]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-37                 [8, 128, 160, 160]        147,456\n",
      "│    │    │    │    └─CALayer: 5-21                     [8, 128, 160, 160]        --\n",
      "│    │    │    │    │    └─AdaptiveAvgPool2d: 6-38      [8, 128, 1, 1]            --\n",
      "│    │    │    │    │    └─Sequential: 6-39             [8, 128]                  8,192\n",
      "│    │    └─Up: 3-10                                    [8, 64, 320, 320]         --\n",
      "│    │    │    └─ConvTranspose2d: 4-24                  [8, 64, 320, 320]         32,768\n",
      "│    │    │    └─nConv2d: 4-25                          [8, 128, 320, 320]        --\n",
      "│    │    │    │    └─Sequential: 5-22                  [8, 128, 320, 320]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-40                 [8, 128, 320, 320]        147,456\n",
      "│    │    │    │    │    └─ReLU: 6-41                   [8, 128, 320, 320]        --\n",
      "│    │    │    │    │    └─Conv2d: 6-42                 [8, 128, 320, 320]        147,456\n",
      "│    │    │    └─Conv2d: 4-26                           [8, 64, 320, 320]         8,192\n",
      "│    │    │    └─CABlock: 4-27                          [8, 64, 320, 320]         --\n",
      "│    │    │    │    └─Sequential: 5-23                  [8, 64, 320, 320]         --\n",
      "│    │    │    │    │    └─Conv2d: 6-43                 [8, 64, 320, 320]         36,864\n",
      "│    │    │    │    │    └─ReLU: 6-44                   [8, 64, 320, 320]         --\n",
      "│    │    │    │    │    └─Conv2d: 6-45                 [8, 64, 320, 320]         36,864\n",
      "│    │    │    │    └─CALayer: 5-24                     [8, 64, 320, 320]         --\n",
      "│    │    │    │    │    └─AdaptiveAvgPool2d: 6-46      [8, 64, 1, 1]             --\n",
      "│    │    │    │    │    └─Sequential: 6-47             [8, 64]                   2,048\n",
      "│    └─Conv2d: 2-7                                      [8, 32, 320, 320]         2,080\n",
      "│    └─CheckNan: 2-8                                    [8, 32, 320, 320]         --\n",
      "│    └─CheckInf: 2-9                                    [8, 32, 320, 320]         --\n",
      "├─Real2Complex: 1-3                                     [8, 16, 320, 320]         --\n",
      "=========================================================================================================\n",
      "Total params: 82,319,456\n",
      "Trainable params: 82,319,456\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (T): 1.73\n",
      "=========================================================================================================\n",
      "Input size (MB): 104.86\n",
      "Forward/backward pass size (MB): 8991.70\n",
      "Params size (MB): 329.28\n",
      "Estimated Total Size (MB): 9425.83\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import models\n",
    "from models import mynn as mynn\n",
    "from models.mynn import functional as myf\n",
    "from train import train\n",
    "from datasets import Fastmri_320p\n",
    "from utils import show\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, in_channels : int = 16, out_channels : int = 16 , depth : int = 4, top_channels : int = 64, dtype = torch.float32, crop_res = False):\n",
    "        super().__init__()\n",
    "        self.unet = models.UNet(in_channels=in_channels*2, out_channels=out_channels*2, depth=depth, top_channels=top_channels, dtype=dtype, crop_res=crop_res,\n",
    "                                norm_layer=None,\n",
    "                                act_layer=nn.ReLU)\n",
    "        self.r2c = mynn.Real2Complex()\n",
    "        self.c2r = mynn.Complex2Real()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data = self.c2r(data)\n",
    "        data = self.unet(data)\n",
    "        data = self.r2c(data)\n",
    "        return data\n",
    "\n",
    "data_augmentation = DataAugmentation(Motion())\n",
    "\n",
    "trainset = Fastmri_320p(trainlist, transform=Loadtransform())\n",
    "valset = Fastmri_320p(vallist, transform = Loadtransform())\n",
    "showset = Fastmri_320p(showlist, transform = Loadtransform())\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "ssim_fn = mynn.loss.MS_SSIM(data_range=1.0, channel=32)\n",
    "\n",
    "def loss_fn(pred, true):\n",
    "    pred = mynn.complex_to_real(pred)\n",
    "    pred = mynn.real_to_complex(true)\n",
    "    return 1-ssim_fn(pred,true)\n",
    "\n",
    "def rsos(x):\n",
    "    return torch.sqrt(torch.sum(x.abs()**2, dim=1,keepdim=True))\n",
    "\n",
    "def show_transform(pred, y, x=None):\n",
    "    # 1 C H W\n",
    "    if x is not None:\n",
    "        x = rsos(x)\n",
    "    y = rsos(y)\n",
    "    pred = rsos(pred)\n",
    "    if x is not None:\n",
    "        return x, y, pred\n",
    "    return y, pred\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataset=trainset,\n",
    "    val_dataset=valset,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=11,\n",
    "    lr = 0.001,\n",
    "    exp_name='unet_radial_moco',\n",
    "    epoch_length=640,\n",
    "    eval_length_train=640,\n",
    "    eval_length_val=64,\n",
    "    augmentation_transform=data_augmentation,\n",
    "    input_transform=lambda data:(data['image_after'], data['image_before']),\n",
    "    metric_transform=lambda x : x.abs(),\n",
    "    show_transform=show_transform,\n",
    "    extra_info={'test':\"1\"},\n",
    "    imshow_dataset=showset,\n",
    "    )\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
